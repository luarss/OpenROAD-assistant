{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b27a57-0b48-4c5e-bed7-3b5d8fac1b18",
   "metadata": {},
   "source": [
    "## Using GitLoader (Langchain) to load git repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6fd0be-ce39-4dba-a5ed-9bd9fd550b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b158dc-ea1f-4ee0-8d29-cc97b5b115ba",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- preprocess md file separately.\n",
    "- how to preprocess code files?\n",
    "\n",
    "\n",
    "## Tips from [here](https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c)\n",
    "- Clean your data. Make sure it is content only and no extraneous tags.\n",
    "- Explore different index types. Perhaps can use keyword based search for certain items, and llamaindex based for others.\n",
    "- Experiment with chunking approach. Suggest to write up individual functions and then combine them into a main file for experiments. (for loop)\n",
    "- Play around with your base prompt. Once again, can use an experiment. Refer to the prompt guide [here](https://arxiv.org/abs/2302.11382)\n",
    "- Do meta-data filtering. Gitloader currently doesn't consider date. But there should be a way to obtain last modified.\n",
    "-  Use query routing. It's useful to have more than one index. For e.g. one that handles the summaries, one that answers flow questions etc. OR just come up with two separate chatbots.\n",
    "- Look into reranking. It is one solution to the issue of discrepancy between similarity and relevance.\n",
    "- Look into transforming the user's query further. [HyDE](https://github.com/texttron/hyde) takes a query, generates a hypothetical response, and then uses both for embedding look up. This can improve performance. [*note that they use GPT3, but we can simply prompt the LLM one more time.*]\n",
    "- Fine-tune your **embedding model**. The embedding model might not be well-suited to our target domain. So we can improve retrieval by fine-tuning first.\n",
    "- Use LLM evaluation frameworks: Langchain-Evaluate, RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a45189a-4c49-45fe-bed0-d5657a2c2a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"# Contributor Covenant Code of Conduct\\n\\n## Our Pledge\\n\\nWe as members, contributors, and leaders pledge to make participation in our\\ncommunity a harassment-free experience for everyone, regardless of age, body\\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\\nidentity and expression, level of experience, education, socio-economic status,\\nnationality, personal appearance, race, religion, or sexual identity\\nand orientation.\\n\\nWe pledge to act and interact in ways that contribute to an open, welcoming,\\ndiverse, inclusive, and healthy community.\\n\\n## Our Standards\\n\\nExamples of behavior that contributes to a positive environment for our\\ncommunity include:\\n\\n* Demonstrating empathy and kindness toward other people\\n* Being respectful of differing opinions, viewpoints, and experiences\\n* Giving and gracefully accepting constructive feedback\\n* Accepting responsibility and apologizing to those affected by our mistakes,\\n  and learning from the experience\\n* Focusing on what is best not just for us as individuals, but for the\\n  overall community\\n\\nExamples of unacceptable behavior include:\\n\\n* The use of sexualized language or imagery, and sexual attention or\\n  advances of any kind\\n* Trolling, insulting or derogatory comments, and personal or political attacks\\n* Public or private harassment\\n* Publishing others' private information, such as a physical or email\\n  address, without their explicit permission\\n* Other conduct which could reasonably be considered inappropriate in a\\n  professional setting\\n\\n## Enforcement Responsibilities\\n\\nCommunity leaders are responsible for clarifying and enforcing our standards of\\nacceptable behavior and will take appropriate and fair corrective action in\\nresponse to any behavior that they deem inappropriate, threatening, offensive,\\nor harmful.\\n\\nCommunity leaders have the right and responsibility to remove, edit, or reject\\ncomments, commits, code, wiki edits, issues, and other contributions that are\\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\\ndecisions when appropriate.\\n\\n## Scope\\n\\nThis Code of Conduct applies within all community spaces, and also applies when\\nan individual is officially representing the community in public spaces.\\nExamples of representing our community include using an official e-mail address,\\nposting via an official social media account, or acting as an appointed\\nrepresentative at an online or offline event.\\n\\n## Enforcement\\n\\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\\nreported to the community leaders responsible for enforcement at\\ncomplaints@openroad.tools.\\nAll complaints will be reviewed and investigated promptly and fairly.\\n\\nAll community leaders are obligated to respect the privacy and security of the\\nreporter of any incident.\\n\\n## Enforcement Guidelines\\n\\nCommunity leaders will follow these Community Impact Guidelines in determining\\nthe consequences for any action they deem in violation of this Code of Conduct:\\n\\n### 1. Correction\\n\\n**Community Impact**: Use of inappropriate language or other behavior deemed\\nunprofessional or unwelcome in the community.\\n\\n**Consequence**: A private, written warning from community leaders, providing\\nclarity around the nature of the violation and an explanation of why the\\nbehavior was inappropriate. A public apology may be requested.\\n\\n### 2. Warning\\n\\n**Community Impact**: A violation through a single incident or series\\nof actions.\\n\\n**Consequence**: A warning with consequences for continued behavior. No\\ninteraction with the people involved, including unsolicited interaction with\\nthose enforcing the Code of Conduct, for a specified period of time. This\\nincludes avoiding interactions in community spaces as well as external channels\\nlike social media. Violating these terms may lead to a temporary or\\npermanent ban.\\n\\n### 3. Temporary Ban\\n\\n**Community Impact**: A serious violation of community standards, including\\nsustained inappropriate behavior.\", metadata={'source': 'CODE_OF_CONDUCT.md', 'file_path': 'CODE_OF_CONDUCT.md', 'file_name': 'CODE_OF_CONDUCT.md', 'file_type': '.md'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The original approach loads too many files. \n",
    "# Instead, focus on Tcl, Cpp files\n",
    "\n",
    "cpp_exts = ['.cpp', 'cc', 'c++',\n",
    "            'hpp', 'hh', 'h++', 'h']\n",
    "other_exts = ['.tcl', '.i', '.py', '.md']\n",
    "exts = cpp_exts + other_exts\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/The-OpenROAD-Project/OpenROAD\",\n",
    "    repo_path=\"./data\",\n",
    "    branch=\"master\",\n",
    "    file_filter = lambda file_path: any(file_path.endswith(ext) for ext in exts)\n",
    ")\n",
    "\n",
    "data = loader.load_and_split()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f5a1d4f-8faa-402a-a865-b88464721ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7037"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81278fc8-5015-4467-93e1-4e6f2ee4209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code is adapted from https://github.com/langchain-ai/langchain/issues/3016\n",
    "def save_docs_to_jsonl(array:Iterable[Document], file_path:str)->None:\n",
    "    with open(file_path, 'w') as jsonl_file:\n",
    "        for doc in array:\n",
    "            jsonl_file.write(doc.json() + '\\n')\n",
    "\n",
    "def load_docs_from_jsonl(file_path)->Iterable[Document]:\n",
    "    array = []\n",
    "    with open(file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            data = json.loads(line)\n",
    "            obj = Document(**data)\n",
    "            array.append(obj)\n",
    "    return array\n",
    "    \n",
    "save_docs_to_jsonl(data,'tempdata/data.jsonl')\n",
    "data2=load_docs_from_jsonl('tempdata/data.jsonl')\n",
    "assert len(data) == len(data2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce71ee8-81a0-4692-b3bb-04d4b0ae18d7",
   "metadata": {},
   "source": [
    "## Chunking Strategies (from Pinecone) [link](https://www.pinecone.io/learn/chunking-strategies)\n",
    "- Fixed-size chunking. The most straightforward is to use Langchain, CharacterTextSplitter\n",
    "- Content-aware chunking. Take advantage of the nature of the content and apply more sophisticated chunking\n",
    "1. Naive splitting: split by `.`, `\\n`\n",
    "```python\n",
    "text = \"...\" # your text<br>\n",
    "docs = text.split(\".\")\n",
    "```\n",
    "\n",
    "2. NLTK\n",
    "```python\n",
    "text = \"...\" # your text\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "text_splitter = NLTKTextSplitter()\n",
    "docs = text_splitter.split_text(text)\n",
    "```\n",
    "\n",
    "3. spaCy\n",
    "```python\n",
    "text = \"...\" # your text\r\n",
    "from langchain.text_splitter import SpacyTextSplitter\r\n",
    "text_splitter = SpaCyTextSplitter()\r\n",
    "docs = text_splitter.split_text(te)\r\n",
    "\r\n",
    "\n",
    "- Recursive Chunking: divide the input text into smaller chunks hierarchically and iteratively.\n",
    "```python\n",
    "text = \"...\" # your text\r\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n",
    "text_splitter = RecursiveCharacterTextSplitter(\r\n",
    "    # Set a really small chunk size, just to show.\r\n",
    "    chunk_size = 256,\r\n",
    "    chunk_overlap  =20\r\n",
    ")\r\n",
    "\r\n",
    "docs = text_splitter.create_documentstext]\n",
    "- Specialized Chunking: Markdown and LateX\n",
    "```python\n",
    "from langchain.text_splitter import MarkdownTextSplitter\r\n",
    "markdown_text = \"...\"\r\n",
    "\r\n",
    "markdown_splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=0)\r\n",
    "docs = markdown_splitter.create_documents([markdown_te)\r\n",
    "`\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```)\r\n",
    "\r\n",
    "\n",
    "```\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d6770-a26c-4167-8ba9-a6b5da9d8441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0ddc7-1c8f-46c9-bd8a-3e6da828ebd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661c921-0332-49d2-8cc0-5c2705c707c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d302ee93-dfba-4e51-9567-9c7e2b0d8c73",
   "metadata": {},
   "source": [
    "## Best chunk size\n",
    "- Preprocessing your data. Remove tags, noise\n",
    "- Select a range of chunk sizes, setup evaluation harness\n",
    "- A good size of question bank is 75. [link](https://www.mattambrogi.com/posts/chunk-size-matters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53541928-2857-4a99-a7f7-5dc3c495fa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b6954-273b-4259-b612-33dc58b7a7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2c4ab-ec51-49a5-9019-b26c9e97b9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345829ac-8ab4-403b-9aeb-6a507f7634f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbb420-e064-427a-a1a4-04ed6c7b393e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
